{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Improving Math Reasoning with a Custom Recipe for Automated Prompt Engineering (DSPy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataset.dataset import get_examples, is_correct\n",
    "from scipy.stats import norm\n",
    "from tensorzero import AsyncTensorZeroGateway, InferenceResponse\n",
    "from tqdm.asyncio import tqdm_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup TensorZero Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = await AsyncTensorZeroGateway.build_http(\n",
    "    gateway_url=\"http://localhost:3000\", timeout=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7473 train examples\n",
      "1319 test examples\n",
      "{'question': 'Jake splits 8 shots of vodka with his friend.  Each shot of vodka is 1.5 ounces.  If the vodka is 50% pure alcohol, how much pure alcohol did Jake drink?\\n', 'answer': 'Jake drank 8/2=<<8/2=4>>4 shots\\nSo he drank 4*1.5=<<4*1.5=6>>6 ounces of vodka\\nThat means he drank 6*.5=<<6*.5=3>>3 ounces of pure alcohol\\n#### 3<|endoftext|>'}\n"
     ]
    }
   ],
   "source": [
    "train_examples = get_examples(\"train\")\n",
    "random.shuffle(train_examples)\n",
    "\n",
    "test_examples = get_examples(\"test\")\n",
    "random.shuffle(test_examples)\n",
    "\n",
    "print(train_examples[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def solve_math_problem(\n",
    "    question: str,\n",
    "    *,\n",
    "    variant_name: Optional[str] = None,\n",
    "    dryrun: bool = False,\n",
    ") -> Optional[InferenceResponse]:\n",
    "    try:\n",
    "        return await t0.inference(\n",
    "            function_name=\"solve_math_problem\",\n",
    "            input={\"messages\": [{\"role\": \"user\", \"content\": {\"question\": question}}]},\n",
    "            cache_options={\"enabled\": \"on\"},\n",
    "            variant_name=variant_name,\n",
    "            dryrun=dryrun,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error ({type(e)}): {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the function below, the only feedback provided to TensorZero is whether the output of the function is correct.\n",
    "We do not provide the correct answer in cases of mistakes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def solve_and_score_math_problem(\n",
    "    example: Dict[str, str],\n",
    "    *,\n",
    "    variant_name: Optional[str] = None,\n",
    "    dryrun: bool = False,\n",
    ") -> Optional[bool]:\n",
    "    # Run the TensorZero function on the example\n",
    "    response = await solve_math_problem(\n",
    "        example[\"question\"], variant_name=variant_name, dryrun=dryrun\n",
    "    )\n",
    "\n",
    "    # Inference failed completely, disregard this example\n",
    "    if response is None:\n",
    "        return None\n",
    "\n",
    "    # Inference succeeded, but the first block is not text, so we consider it incorrect\n",
    "    first_block = response.content[0]\n",
    "    if first_block.type != \"text\":\n",
    "        return False\n",
    "\n",
    "    # Inference succeeded, and the first block is text, so we score the example\n",
    "    correct = is_correct(first_block.text, example)\n",
    "\n",
    "    # Store the feedback in the database\n",
    "    # (skip if dryrun since we're not storing the inferences, which will trigger an error)\n",
    "    if not dryrun:\n",
    "        await t0.feedback(\n",
    "            metric_name=\"correct\",\n",
    "            value=correct,\n",
    "            inference_id=response.inference_id,\n",
    "            dryrun=dryrun,\n",
    "        )\n",
    "\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Examples\n",
    "\n",
    "Run the TensorZero function on the training examples, grade the answers, and store the feedback in the database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the number of concurrent inferences to avoid rate limiting\n",
    "MAX_CONCURRENT_INFERENCES = 100\n",
    "\n",
    "semaphore = asyncio.Semaphore(MAX_CONCURRENT_INFERENCES)\n",
    "\n",
    "\n",
    "async def run_inference(\n",
    "    example: Dict[str, str], *, variant_name: Optional[str] = None, dryrun: bool = False\n",
    ") -> Optional[bool]:\n",
    "    async with semaphore:\n",
    "        return await solve_and_score_math_problem(\n",
    "            example, variant_name=variant_name, dryrun=dryrun\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:18.693805Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.695826Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.696015Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.696172Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.696326Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.696448Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.696577Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.696718Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.696857Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.696986Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.697115Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.697245Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.697365Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.697521Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.697631Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.697745Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.697842Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.697942Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.698040Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.698132Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.698226Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.698335Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.698457Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.698588Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.698701Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.698828Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.698964Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.699085Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.699209Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.699341Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.699450Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.699560Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.699708Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.699830Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.699965Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.700097Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.700193Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.700335Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.700439Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.700568Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.700704Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.700825Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.700928Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.701034Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.701129Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.701232Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.701338Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.701534Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.701695Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.701837Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.701959Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.702070Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.702178Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.702283Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.702383Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.702482Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.702682Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.702970Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.703116Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.703250Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.703365Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.703473Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.703750Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.704063Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.704185Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.704281Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.704385Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.704483Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.704578Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.704954Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.705081Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.705181Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.705274Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.705400Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.705501Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.705608Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.705702Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.705788Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.865987Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.866400Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.868930Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.869175Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.869363Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.869527Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.869673Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.869810Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.869959Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.870362Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.870582Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.870754Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.870910Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.871077Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.871246Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.871408Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.889170Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.890126Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.890471Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.890642Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.890796Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:18.890929Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:   0%|          | 1/1000 [00:02<45:39,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:21.414270Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.416805Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.422061Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.422792Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.423468Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.423891Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.424356Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.424971Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.425072Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.426024Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.427946Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.428765Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.441974Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.442502Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.442948Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.442972Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.443706Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.444068Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.444618Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.444773Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.445989Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.446173Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.496907Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.497677Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.497685Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.498380Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.498834Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.498889Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.499276Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.499519Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.500137Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.500274Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.500431Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.501224Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.501313Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.502059Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.502075Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.502831Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.502868Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.503690Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.504075Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.504698Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.505197Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.505828Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.505960Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.506435Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.506771Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.507199Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.507570Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.508034Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:   4%|▍         | 40/1000 [00:03<00:50, 19.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:21.725172Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.726456Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.730710Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.730710Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.730710Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.731289Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.731297Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.732702Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.732786Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.732869Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.732891Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.733009Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.733118Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array ofError (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      " content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.733252Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.733484Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.734313Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.734445Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.735609Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.736435Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.736652Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.738837Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.739299Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.739308Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:21.739299Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.740417Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.740571Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.740965Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.741138Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:21.838400Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:21.839300Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.005924Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.007325Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.190630Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.191715Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.225548Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.226117Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.227077Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.227699Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:22.227732Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.228687Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:   5%|▍         | 49/1000 [00:03<00:58, 16.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:22.584271Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.585266Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:22.585782Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.586480Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.588189Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.588823Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.589159Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.589779Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.589912Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:22.590925Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:22.591852Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.593705Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.593862Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.593999Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.594293Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.595032Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.596649Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.597253Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:22.597798Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.598479Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.608187Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.608872Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.631522Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:22.632013Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.632482Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.632959Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.638138Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.639028Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.642386Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.643239Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.646452Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.647146Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.784305Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:   6%|▌         | 62/1000 [00:04<00:41, 22.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:22.785054Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.936315Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.937203Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.938870Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.940311Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:22.971178Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:22.972030Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:23.059693Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:23.060980Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:   7%|▋         | 68/1000 [00:04<00:53, 17.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:23.276775Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:23.278372Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:23.452563Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:23.453399Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:23.459569Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:23.460557Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:23.465811Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:23.467011Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:23.477573Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\u001b[2m2025-08-12T09:59:23.478771Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:23.480081Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:23.481561Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:   8%|▊         | 81/1000 [00:05<00:41, 22.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:23.701930Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:23.703239Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:23.704497Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:23.706738Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:23.712655Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:23.713543Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:23.719078Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:23.719473Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:23.719978Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:23.720411Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:23.722520Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:23.723355Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:23.725033Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:23.725806Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:23.730268Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:23.731159Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:23.862598Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:23.863372Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:23.863592Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:23.865951Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:23.866092Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:23.867955Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:   8%|▊         | 85/1000 [00:05<00:39, 23.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:23.995693Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:23.996774Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:24.000816Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:   9%|▉         | 89/1000 [00:05<00:41, 21.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:24.219191Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:24.220339Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:24.223572Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:24.224002Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:24.224439Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:24.224976Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:24.226627Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:24.228161Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:24.258462Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:24.259302Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:24.282684Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:24.283492Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:   9%|▉         | 93/1000 [00:05<00:42, 21.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:24.424084Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:24.425462Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:24.426694Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199321, Requested 1589. Please try again in 273ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:24.428527Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:24.432010Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:24.432842Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:24.474900Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1642. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:24.475647Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  10%|█         | 102/1000 [00:06<00:44, 20.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:24.764832Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:24.765204Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:24.766276Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:24.768151Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:24.771221Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:24.772094Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:24.796633Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:24.797506Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:24.861133Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:24.861871Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:24.943847Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:24.944603Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:24.957084Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:24.958016Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  11%|█         | 106/1000 [00:06<00:39, 22.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:24.983044Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:24.984264Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:25.040775Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 138. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.041668Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:25.046379Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 104. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.047268Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  11%|█         | 109/1000 [00:06<00:41, 21.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:25.197904Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.199312Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:25.209664Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1628. Please try again in 488ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.210515Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:25.212534Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.213332Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:25.247081Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1617. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.247852Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:25.262430Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 102. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.263190Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  12%|█▏        | 118/1000 [00:07<00:46, 18.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:25.700232Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.701495Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:25.703290Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199871, Requested 185. Please try again in 16ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.705119Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:25.706917Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.707719Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:25.709398Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:25.709856Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 121. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.710383Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.711002Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:25.768546Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1599. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.769352Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:25.835528Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.836161Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:25.836669Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:25.837280Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 116. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.839513Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1652. Please try again in 495ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.840426Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:25.889228Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.890227Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:25.898137Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1611. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.899116Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  13%|█▎        | 128/1000 [00:07<00:32, 27.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:25.909105Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199270, Requested 1605. Please try again in 262ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.910888Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:25.952231Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 126. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1605. Please try again in 481ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.953305Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:25.977801Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 130. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.978549Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:25.984691Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:25.985209Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199006, Requested 1632. Please try again in 191ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 153. Please try again in 45ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1591. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 112. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:25.985863Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:25.986349Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:26.052944Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 114. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:26.053841Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  13%|█▎        | 132/1000 [00:07<00:38, 22.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:26.162875Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1586. Please try again in 475ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:26.164039Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 101. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:26.164483Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:26.165258Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:26.317844Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 155. Please try again in 46ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1634. Please try again in 490ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:26.318605Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:26.318862Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:26.319581Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:26.321585Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 133. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:26.322897Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:26.323544Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1638. Please try again in 491ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:26.324151Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:26.360215Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1585. Please try again in 475ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:26.360962Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  14%|█▎        | 136/1000 [00:08<00:57, 14.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:26.816969Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1638. Please try again in 491ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:26.818264Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:26.825434Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 134. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:26.826425Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:26.826757Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 154. Please try again in 46ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:26.827446Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  14%|█▍        | 139/1000 [00:08<01:17, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:27.315832Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1577. Please try again in 473ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.316439Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:27.316439Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:27.317303Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.320312Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1625. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 146. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.321588Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.332096Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1599. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.332761Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1610. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.332872Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.333763Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.349171Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 173. Please try again in 51ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.349844Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.362354Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 114. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1593. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.363283Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.376167Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1591. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.376875Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.379740Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.380480Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.385759Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.386461Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.402511Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1615. Please try again in 484ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 136. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.403272Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  17%|█▋        | 169/1000 [00:09<00:21, 37.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:27.593523Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.594744Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.604983Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 128. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1608. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.605863Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.660646Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1633. Please try again in 489ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.661422Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:27.661911Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1617. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 138. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.662648Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.663363Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 130. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.663929Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:27.664335Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1702. Please try again in 510ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 223. Please try again in 66ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.664943Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:27.665020Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 142. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.665912Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.670131Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 118. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.670860Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.671375Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 144. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.672237Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.674683Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1615. Please try again in 484ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.675482Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.676422Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 163. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1642. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.678155Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.680105Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1641. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.680910Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.681180Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.681824Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.682308Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 140. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.683012Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.683968Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 122. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.684731Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.685419Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1609. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.685833Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:27.686410Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1646. Please try again in 493ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.686852Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1611. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 132. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.687436Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.688198Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.688284Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:27.689510Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.699582Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:27.700174Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:27.700174Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1620. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1602. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 123. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.701301Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.703055Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.703207Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.743512Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1648. Please try again in 494ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.744040Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 122. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.744417Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.744811Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.746181Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 173. Please try again in 51ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.746866Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:27.752247Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 135. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:27.753009Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  18%|█▊        | 177/1000 [00:09<00:25, 32.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:28.052163Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1611. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:28.053435Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:28.053816Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 113. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:28.054517Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:28.054804Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:28.056045Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:28.058418Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:28.058653Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  18%|█▊        | 183/1000 [00:09<00:31, 25.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:28.388289Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:28.389443Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:28.455657Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1623. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:28.456414Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:28.458254Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1602. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:28.458979Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:28.462501Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 159. Please try again in 47ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:28.463269Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:28.623461Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 177. Please try again in 53ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:28.624856Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:28.637289Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1619. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:28.638106Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:28.638567Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 209. Please try again in 62ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:28.639348Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:28.647133Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 114. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1593. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:28.647956Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  19%|█▉        | 188/1000 [00:10<00:39, 20.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:28.885441Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:28.886942Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:28.948363Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 132. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:28.949442Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:29.006663Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:29.331846Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  19%|█▉        | 192/1000 [00:11<01:09, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:29.881303Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 146. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:29.882355Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:29.886271Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 139. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:29.886968Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:29.889993Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 105. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:29.890625Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:29.918758Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 129. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1609. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:29.919672Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:29.923543Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:29.924490Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  20%|█▉        | 197/1000 [00:11<01:03, 12.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:30.181086Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  20%|██        | 200/1000 [00:11<01:04, 12.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:30.442816Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1592. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 113. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:30.443869Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:30.444534Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1607. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:30.445153Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:30.445539Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 126. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1605. Please try again in 481ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:30.446146Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:30.461143Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 209. Please try again in 62ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1689. Please try again in 506ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:30.461900Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  20%|██        | 202/1000 [00:12<01:10, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:30.702425Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 119. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1598. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:30.703444Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:30.792877Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:30.793590Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:30.796235Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:30.796851Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:30.797255Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1599. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:30.797820Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  21%|██        | 206/1000 [00:12<01:14, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:31.130485Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 155. Please try again in 46ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1635. Please try again in 490ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:31.131976Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  21%|██        | 208/1000 [00:12<01:22,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:31.415151Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1605. Please try again in 481ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 126. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:31.416372Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:31.445300Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:31.445685Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 163. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1657. Please try again in 497ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:31.446151Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:31.448032Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:31.460256Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  21%|██        | 211/1000 [00:13<01:21,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:31.746931Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 146. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:31.748591Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:31.752939Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 122. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:31.753658Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  21%|██▏       | 213/1000 [00:13<01:30,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:32.061039Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:32.061978Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:32.062317Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1600. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:32.065364Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:32.094842Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 151. Please try again in 45ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1630. Please try again in 488ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:32.095544Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:32.108004Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 146. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:32.108904Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:32.138204Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1591. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 112. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:32.139113Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  22%|██▏       | 220/1000 [00:13<01:04, 12.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:32.286917Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:32.433956Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 144. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 87. Please try again in 26ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:32.434546Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:32.434981Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:32.435453Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:32.435768Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:32.438426Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:32.443234Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 111. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:32.444003Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:32.466660Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 119. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:32.467484Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:32.467951Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:32.467965Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 169. Please try again in 50ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1636. Please try again in 490ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:32.469264Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:32.469422Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  23%|██▎       | 226/1000 [00:13<00:44, 17.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:32.598471Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:32.614068Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 134. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:32.614940Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:32.626046Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 138. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:32.626786Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:32.646337Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:32.647333Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:32.651619Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1596. Please try again in 478ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 116. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:32.652381Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  24%|██▎       | 236/1000 [00:14<00:37, 20.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:32.904162Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:32.905166Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 113. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1592. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:32.905802Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:32.907591Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:32.910744Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 132. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1611. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 145. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1625. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:32.911229Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:32.911688Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:32.912169Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:32.915513Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 130. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1609. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:32.916245Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:33.042802Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1642. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 162. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:33.043712Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  24%|██▍       | 239/1000 [00:14<00:36, 21.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:33.172623Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 126. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1605. Please try again in 481ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:33.173613Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:33.174211Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 223. Please try again in 66ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1702. Please try again in 510ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:33.174886Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:33.175377Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 105. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1584. Please try again in 475ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:33.176066Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  24%|██▍       | 242/1000 [00:14<00:39, 18.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:33.379881Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 111. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:33.380852Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 143. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:33.381224Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:33.381806Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:33.382926Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 128. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:33.383558Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:33.436104Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:33.436500Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 104. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1583. Please try again in 474ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 121. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:33.436947Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:33.437375Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:33.437902Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:33.438048Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  25%|██▍       | 248/1000 [00:15<00:47, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:33.674528Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 192. Please try again in 57ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:33.675750Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:33.676169Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 131. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1610. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:33.678320Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:33.840318Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 121. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1600. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:33.841027Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:33.841536Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:33.843843Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  26%|██▌       | 255/1000 [00:15<00:35, 21.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:33.932195Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1615. Please try again in 484ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 135. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:33.933470Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:33.933877Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 142. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:33.934572Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:33.952225Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 111. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:33.952961Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.058718Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 130. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.059470Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1601. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.059508Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:34.060213Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.061775Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1591. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.062810Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.063814Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1598. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.065841Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.071612Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 126. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199041, Requested 1605. Please try again in 193ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.072451Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  26%|██▌       | 261/1000 [00:15<00:36, 20.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:34.177546Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.178917Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.338383Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.339141Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 129. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198980, Requested 1608. Please try again in 176ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.339158Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.339988Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.354582Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.355260Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  27%|██▋       | 268/1000 [00:15<00:28, 26.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:34.418257Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:34.418968Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 121. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 129. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 118. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.419699Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:34.419707Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.420357Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.420447Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:34.420792Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1617. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.421683Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.423776Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.424523Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.429870Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198645, Requested 1610. Please try again in 76ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 131. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.430869Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.544631Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1606. Please try again in 481ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.545382Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.566248Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1605. Please try again in 481ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.566963Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.568491Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.569326Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.572314Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.573572Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.574749Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.575574Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.608848Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 173. Please try again in 51ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1653. Please try again in 495ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.609597Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.609798Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1622. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 143. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.610586Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  28%|██▊       | 275/1000 [00:16<00:28, 25.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:34.837655Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1607. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199913, Requested 128. Please try again in 12ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.838185Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:34.839049Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1644. Please try again in 493ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.840983Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.850000Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 167. Please try again in 50ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1646. Please try again in 493ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.850730Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.870821Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 130. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.871463Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.874749Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 121. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.875386Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.877380Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 117. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.877937Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 187. Please try again in 56ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.878284Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.878781Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:34.924519Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 130. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:34.925378Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  29%|██▉       | 288/1000 [00:16<00:25, 27.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:35.184402Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 115. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.185177Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.187807Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199621, Requested 1614. Please try again in 370ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 134. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.188401Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.188946Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 109. Please try again in 32ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199093, Requested 1588. Please try again in 204ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.189634Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.191765Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1592. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.192520Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.198797Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1611. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.199868Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.299768Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 157. Please try again in 47ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.300388Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:35.300523Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.300874Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:35.301975Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1613. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 134. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 110. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 123. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.303772Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.304306Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.304445Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.309486Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1604. Please try again in 481ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 125. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 162. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.310067Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:35.310371Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.310832Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  31%|███       | 306/1000 [00:16<00:16, 41.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:35.521257Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198841, Requested 1626. Please try again in 140ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 146. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.522495Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.525041Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198472, Requested 1597. Please try again in 20ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 118. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.525700Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.525700Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.526446Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.530977Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.531705Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.538687Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198466, Requested 1649. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.539433Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.547135Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.547966Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.560777Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.562154Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.582743Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.584050Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.584303Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1588. Please try again in 476ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 109. Please try again in 32ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.585144Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.588699Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1591. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.589622Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.599457Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199679, Requested 1621. Please try again in 390ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.600687Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.605943Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.607058Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.641571Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 110. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1589. Please try again in 476ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.642327Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  31%|███       | 312/1000 [00:17<00:21, 32.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:35.920698Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1614. Please try again in 484ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.921607Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.932938Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.933635Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.937247Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199299, Requested 1673. Please try again in 291ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.937946Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:35.937997Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.938714Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.939567Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199725, Requested 1629. Please try again in 406ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.940072Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:35.940190Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.940930Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:35.942870Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1613. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:35.943521Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:36.017925Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:36.018768Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  32%|███▏      | 317/1000 [00:17<00:30, 22.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:36.338271Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 134. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:36.339543Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:36.341834Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1642. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:36.342570Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:36.408447Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1598. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 118. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:36.409181Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:36.439246Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:36.440050Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:36.452527Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 116. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:36.453478Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:36.455959Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199853, Requested 1650. Please try again in 450ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:36.456728Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  32%|███▏      | 324/1000 [00:18<00:31, 21.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:36.575422Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1606. Please try again in 481ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 127. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:36.576291Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:36.592263Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 158. Please try again in 47ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:36.592953Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:36.604008Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1615. Please try again in 484ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 136. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:36.604795Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:36.746142Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 155. Please try again in 46ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199231, Requested 1634. Please try again in 259ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:36.747050Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  33%|███▎      | 327/1000 [00:18<00:32, 20.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:36.871933Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199902, Requested 124. Please try again in 7ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198967, Requested 1603. Please try again in 171ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:36.873266Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:36.918359Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199893, Requested 1606. Please try again in 449ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:36.919055Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:36.919274Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1628. Please try again in 488ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:36.919901Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:36.920781Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:36.922129Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:36.930559Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1669. Please try again in 500ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 190. Please try again in 57ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:36.931268Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  34%|███▎      | 336/1000 [00:18<00:29, 22.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:37.108664Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 165. Please try again in 49ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.109937Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.111161Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 153. Please try again in 45ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.113376Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.120031Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 180. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.120840Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.173936Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1603. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.174596Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.181926Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1634. Please try again in 490ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.182927Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.183924Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 156. Please try again in 46ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.184744Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.293543Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1638. Please try again in 491ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.294387Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.306233Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.307067Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  34%|███▍      | 339/1000 [00:18<00:28, 22.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:37.324210Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1621. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.325310Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.422265Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 122. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1601. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.422994Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.423980Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199814, Requested 1606. Please try again in 426ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.424909Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:37.425569Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.426075Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:37.426075Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:37.426264Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1619. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.428019Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.428617Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  34%|███▍      | 344/1000 [00:18<00:24, 26.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:37.550976Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199455, Requested 1661. Please try again in 334ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.552496Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.556369Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.557149Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:37.557182Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 126. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199880, Requested 1606. Please try again in 445ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.558128Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.567010Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1640. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.567855Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.568340Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 128. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.568966Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.570210Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 125. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1604. Please try again in 481ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.571070Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.572660Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 112. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1591. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.573669Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:37.573703Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 108. Please try again in 32ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199843, Requested 1587. Please try again in 429ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.574525Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.586522Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 103. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199716, Requested 1582. Please try again in 389ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.587395Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 164. Please try again in 49ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.587395Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:37.587973Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.588417Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:37.588812Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.589481Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:37.589531Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199881, Requested 1619. Please try again in 450ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.590522Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 124. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1603. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.591245Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.607005Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.607672Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.608089Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.608579Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.609596Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:37.609596Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1599. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 119. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1599. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 120. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.611141Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.611328Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  36%|███▌      | 361/1000 [00:19<00:15, 42.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:37.809316Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1615. Please try again in 484ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.811375Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:37.811624Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1631. Please try again in 489ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:37.815665Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  37%|███▋      | 369/1000 [00:19<00:19, 32.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:38.073386Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1607. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.074603Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.074823Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1660. Please try again in 498ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.075244Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1583. Please try again in 474ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.075336Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:38.075873Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.076221Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:38.076628Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.076797Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199406, Requested 1601. Please try again in 302ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.080626Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.084068Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.084817Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.201191Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199902, Requested 1609. Please try again in 453ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 130. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.201956Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.205749Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.206551Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.208591Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198689, Requested 1597. Please try again in 85ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 118. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.209381Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.224222Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 178. Please try again in 53ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199363, Requested 1658. Please try again in 306ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.224943Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.248382Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.249224Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  38%|███▊      | 383/1000 [00:20<00:19, 32.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:38.541422Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 170. Please try again in 51ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.542589Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.545442Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199015, Requested 1636. Please try again in 195ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 157. Please try again in 47ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.546785Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.548530Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 114. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.549413Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.551811Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1593. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 113. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.552531Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.552875Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198676, Requested 1599. Please try again in 82ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.553495Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.556651Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:38.556651Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1625. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 145. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198866, Requested 1664. Please try again in 159ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.557648Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.557811Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.565832Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 113. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1592. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.566758Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.634965Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 135. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.635660Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.692919Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 122. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.693698Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.697729Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1591. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 112. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.698318Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 144. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199929, Requested 1623. Please try again in 465ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.698747Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.699253Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.700240Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 116. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1596. Please try again in 478ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 167. Please try again in 50ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.700657Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:38.701071Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.701591Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.702366Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.703066Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.704285Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.705109Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.705430Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:38.705769Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1593. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 149. Please try again in 44ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.706071Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:38.706538Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.707061Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.707074Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:38.707223Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1603. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 124. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.708042Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.710049Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1606. Please try again in 481ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 127. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.710852Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  40%|███▉      | 395/1000 [00:20<00:14, 42.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:38.863590Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.864705Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.992896Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1658. Please try again in 497ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.993937Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.994381Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1600. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.995148Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:38.997546Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 121. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1601. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:38.998432Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  40%|████      | 400/1000 [00:20<00:18, 31.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:39.161847Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 123. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199106, Requested 1602. Please try again in 212ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.163198Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.166749Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1605. Please try again in 481ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.167581Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  40%|████      | 404/1000 [00:20<00:23, 25.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:39.396086Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.397925Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.421265Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198824, Requested 1659. Please try again in 144ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.422034Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.454052Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.454990Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.458022Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1588. Please try again in 476ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.458765Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.461741Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 126. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.462549Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.463820Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198822, Requested 1599. Please try again in 126ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.464530Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.467025Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1596. Please try again in 478ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.467703Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.468107Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.468650Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  42%|████▏     | 421/1000 [00:21<00:16, 34.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:39.803972Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1603. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.804950Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.808838Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.809766Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.819238Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 125. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.820022Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.837123Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.837734Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.841099Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1622. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 143. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.841986Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.857570Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 150. Please try again in 45ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1629. Please try again in 488ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.858332Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.858841Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1633. Please try again in 489ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.859485Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.868798Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198624, Requested 1655. Please try again in 83ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.869583Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.873267Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1602. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.873998Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.881934Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.882648Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.887928Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 122. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1601. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.888663Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.899068Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 109. Please try again in 32ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.899821Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.905028Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1623. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.905801Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.960488Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:39.960975Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 145. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1606. Please try again in 481ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.961678Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.962384Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.964409Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 119. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1598. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.964854Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:39.964869Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1616. Please try again in 484ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 117. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1597. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:39.965650Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.966329Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:39.966537Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  43%|████▎     | 433/1000 [00:21<00:15, 37.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:40.028761Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:40.029271Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:40.030306Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:40.033429Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:40.174624Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1598. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:40.175548Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:40.180645Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199182, Requested 1598. Please try again in 234ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199917, Requested 142. Please try again in 17ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1621. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:40.181095Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:40.181610Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 140. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:40.182222Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:40.182323Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:40.183259Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:40.185631Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:40.186206Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:40.186287Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:40.186752Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1645. Please try again in 493ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 102. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198799, Requested 1581. Please try again in 114ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:40.188801Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:40.188924Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:40.225861Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:40.226658Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:40.227712Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1600. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:40.228574Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  44%|████▍     | 441/1000 [00:21<00:14, 37.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:40.236823Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 112. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1591. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:40.237913Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:40.242977Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:40.243411Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1612. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 117. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:40.244047Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:40.244701Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:40.400730Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:40.436742Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 159. Please try again in 47ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:40.439292Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  45%|████▍     | 446/1000 [00:22<00:25, 21.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:40.773375Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199215, Requested 1601. Please try again in 244ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:40.774164Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:40.776010Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1672. Please try again in 501ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:40.776747Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:40.791163Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:40.791873Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:40.943925Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 154. Please try again in 46ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199644, Requested 1634. Please try again in 383ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:40.944805Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:40.973831Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 159. Please try again in 47ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:40.975818Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:40.976480Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 124. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:40.978309Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:40.979902Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:40.980630Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  45%|████▌     | 450/1000 [00:22<00:29, 18.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:41.287678Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.288815Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:41.293979Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 161. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.295176Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:41.334450Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 117. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.335262Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:41.384736Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1632. Please try again in 489ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 153. Please try again in 45ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.385365Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:41.387814Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.388509Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  46%|████▌     | 458/1000 [00:23<00:27, 19.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:41.587917Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 113. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.589137Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:41.618675Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 162. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.619455Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:41.636086Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1649. Please try again in 494ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.636844Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:41.689635Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1601. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.690351Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:41.702903Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.703678Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:41.721912Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 158. Please try again in 47ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.722651Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  46%|████▌     | 461/1000 [00:23<00:26, 19.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:41.822823Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1608. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 128. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.824114Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:41.839545Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1592. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.840254Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:41.841683Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 130. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199847, Requested 1609. Please try again in 436ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.842582Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:41.846394Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1602. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 123. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.847193Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:41.849177Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 119. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.849861Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:41.852362Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1628. Please try again in 488ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.853085Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:41.853811Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 115. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.854576Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:41.869171Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.869853Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:41.911653Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199721, Requested 1675. Please try again in 418ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 196. Please try again in 58ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:41.912420Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  47%|████▋     | 470/1000 [00:23<00:20, 25.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:42.060953Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.062588Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:42.063000Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:42.064757Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 159. Please try again in 47ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 122. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.065620Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:42.066194Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:42.070126Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1619. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.070870Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:42.157339Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 148. Please try again in 44ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.158135Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:42.159502Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1605. Please try again in 481ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.160248Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  48%|████▊     | 479/1000 [00:23<00:23, 22.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:42.353041Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1590. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 110. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.354309Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:42.360558Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1601. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.361385Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:42.526270Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199350, Requested 1650. Please try again in 300ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 118. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.526948Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:42.527078Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:42.528010Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  48%|████▊     | 485/1000 [00:24<00:24, 21.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:42.720549Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.721516Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.721514Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:42.722303Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:42.726014Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.726827Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:42.727426Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199848, Requested 1627. Please try again in 442ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.729780Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:42.837373Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.838118Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:42.845743Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 139. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199567, Requested 1618. Please try again in 355ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.846596Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:42.871201Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 104. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1584. Please try again in 475ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.871954Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:42.875175Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1627. Please try again in 488ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.875996Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:42.876660Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 120. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199865, Requested 1599. Please try again in 439ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.877457Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:42.878320Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.879114Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:42.882628Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.883395Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:42.932856Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199899, Requested 1626. Please try again in 457ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:42.934140Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  51%|█████     | 506/1000 [00:24<00:12, 38.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:43.160990Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.162155Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:43.162569Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.163261Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.165336Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199927, Requested 1628. Please try again in 466ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.166264Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.167486Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.168180Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.174626Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1638. Please try again in 491ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.175198Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.175198Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:43.175805Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.176759Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.177003Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.235709Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1635. Please try again in 490ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.236594Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.238431Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 139. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.239369Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.240635Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199965, Requested 1585. Please try again in 465ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.241487Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.245030Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.245805Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.247307Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 137. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199361, Requested 1616. Please try again in 293ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.248048Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.252207Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 122. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.253077Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.255992Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 126. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1606. Please try again in 481ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.256832Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.302072Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:43.302626Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:43.302626Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1608. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1615. Please try again in 484ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.303304Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.304308Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199484, Requested 1604. Please try again in 326ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199926, Requested 125. Please try again in 15ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.305799Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1617. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.307829Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.308144Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  51%|█████     | 511/1000 [00:24<00:13, 35.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:43.385983Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.387269Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.470115Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.471219Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.480279Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.481115Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.487112Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1616. Please try again in 484ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.487953Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.520935Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 163. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1643. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.522256Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  52%|█████▏    | 516/1000 [00:24<00:13, 36.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:43.601675Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1598. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.602192Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 128. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.603168Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.603388Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:43.603390Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:43.603407Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:43.603432Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:43.603482Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:43.604467Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1599. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1620. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 123. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1602. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.607018Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.607221Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.607324Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.607415Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1585. Please try again in 475ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 106. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.608887Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.612050Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 115. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1594. Please try again in 478ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.613091Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.616070Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.616978Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.619925Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 102. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.620715Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.621160Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:43.621160Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:43.621505Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:43.621822Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1601. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199695, Requested 1589. Please try again in 385ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 110. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1619. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 134. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1613. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.622872Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.623199Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.623329Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.623856Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:43.675180Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 119. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.675938Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  53%|█████▎    | 530/1000 [00:25<00:09, 47.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:43.804754Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 197. Please try again in 59ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1676. Please try again in 502ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:43.806240Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  54%|█████▎    | 535/1000 [00:25<00:14, 31.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:44.095733Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199734, Requested 1616. Please try again in 405ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.097312Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:44.100004Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:44.100529Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199303, Requested 1603. Please try again in 271ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.101130Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:44.101680Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:44.102016Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198721, Requested 1598. Please try again in 95ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.102693Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:44.176197Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1592. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.177558Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:44.178754Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1617. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.180227Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.180606Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:44.181957Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  54%|█████▍    | 543/1000 [00:25<00:15, 29.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:44.328717Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:44.328746Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.330341Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:44.331083Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:44.333062Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1602. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.335481Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:44.444744Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 128. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.445583Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:44.465836Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.466829Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:44.469599Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1634. Please try again in 490ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.470556Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:44.547208Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.548610Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:44.549362Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.550234Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:44.551980Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1595. Please try again in 478ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.552783Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:44.556995Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1603. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.557858Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  55%|█████▌    | 551/1000 [00:26<00:19, 22.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:44.860950Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 110. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1589. Please try again in 476ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.862143Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:44.862659Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1602. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 123. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.864938Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:44.967134Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199780, Requested 1653. Please try again in 429ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.968047Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:44.972068Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.973111Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:44.983639Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 157. Please try again in 47ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.984559Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:44.988157Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:44.989112Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.021999Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.022992Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.025784Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 128. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.026531Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.047762Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 118. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.048642Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.049584Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1600. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 121. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.050384Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.052516Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199854, Requested 163. Please try again in 5ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.053219Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.053219Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.054424Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.054607Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1619. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.055489Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.058768Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1598. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.059534Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  56%|█████▋    | 565/1000 [00:26<00:10, 42.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:45.062686Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 151. Please try again in 45ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.063692Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.065871Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 139. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.066721Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.069002Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1648. Please try again in 494ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 169. Please try again in 50ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.070075Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.074474Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1613. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.075062Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.089993Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:45.089993Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:45.090762Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:45.090762Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 129. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1608. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1651. Please try again in 495ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 125. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1635. Please try again in 490ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.091814Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.092347Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.092497Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.092598Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.095617Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 120. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.096359Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.099531Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.100568Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.100626Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 121. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1601. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.101505Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  58%|█████▊    | 579/1000 [00:26<00:09, 42.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:45.265600Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:45.266330Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:45.266328Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:45.267205Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1589. Please try again in 476ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 110. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 123. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1593. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 113. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.268401Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.271489Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.271832Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.272060Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.360499Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1610. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 131. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.361475Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.398121Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:45.398575Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198888, Requested 1597. Please try again in 145ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 118. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1596. Please try again in 478ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.399397Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.400227Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  59%|█████▉    | 590/1000 [00:26<00:09, 41.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:45.488628Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 116. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.490424Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.496054Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 139. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1618. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.497311Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.500385Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.503668Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.529893Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1617. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.530851Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.532626Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.533589Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.536831Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1607. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.537790Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.540687Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199632, Requested 1623. Please try again in 376ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 144. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.542254Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.588394Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.589272Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.665706Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:45.666189Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 116. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.666656Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:45.666835Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.667561Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.668210Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.670112Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:45.670646Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:45.670646Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:45.670650Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 104. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199238, Requested 1583. Please try again in 246ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198420, Requested 1614. Please try again in 10ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 135. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 146. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1625. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1628. Please try again in 488ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.673501Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.674502Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.674679Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.674908Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.682996Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199977, Requested 124. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.684076Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.703785Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1597. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.705268Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:45.706755Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199939, Requested 1581. Please try again in 456ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 102. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:45.707753Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  60%|██████    | 602/1000 [00:27<00:15, 26.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:46.103897Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198592, Requested 1583. Please try again in 52ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 104. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.105222Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.114824Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.115589Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.298869Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.299757Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.300249Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1653. Please try again in 495ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.301033Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.302868Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 117. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198928, Requested 1597. Please try again in 157ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.303736Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.308716Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:46.309298Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 157. Please try again in 47ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 138. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198510, Requested 1580. Please try again in 27ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.310213Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 118. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.310294Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.310628Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:46.310890Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.311204Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:46.311811Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.312287Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.313160Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  61%|██████    | 608/1000 [00:27<00:15, 25.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:46.553333Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.555109Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.559898Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1610. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 115. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.560343Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.560343Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:46.560848Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.560946Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:46.561022Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:46.561171Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 147. Please try again in 44ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1626. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 121. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198852, Requested 1584. Please try again in 130ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 105. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 119. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "025-08-12T09:59:46.561199Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:46.561586Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.562716Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.563161Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.563300Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.563389Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.563469Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.566735Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198666, Requested 1629. Please try again in 88ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 113. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.566735Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:46.567723Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.567867Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.570058Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:46.570058Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:46.570658Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 113. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.571919Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.572222Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.572915Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:46.572923Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.573816Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.574316Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 123. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.574938Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.575522Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.576296Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.581386Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:46.581801Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 149. Please try again in 44ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 118. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.582422Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.582919Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:46.582996Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.583818Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.585725Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1618. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.586536Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.591126Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 124. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1603. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.591923Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  63%|██████▎   | 634/1000 [00:28<00:08, 41.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:46.795404Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:46.795404Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 167. Please try again in 50ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1646. Please try again in 493ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 115. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1594. Please try again in 478ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.796934Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.797089Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.932057Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1589. Please try again in 476ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.932975Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.935361Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 141. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.936434Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.950251Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1638. Please try again in 491ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 159. Please try again in 47ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.951193Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.951556Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1625. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.952206Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.981592Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 149. Please try again in 44ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1628. Please try again in 488ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.982477Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.985259Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1612. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:46.986080Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:46.999310Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 171. Please try again in 51ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.000149Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.006900Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1587. Please try again in 476ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199928, Requested 156. Please try again in 25ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1635. Please try again in 490ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.007421Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:47.007928Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.008508Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.010083Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:47.010580Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1624. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 181. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.011140Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.011686Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.014449Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1639. Please try again in 491ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.015233Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  65%|██████▍   | 647/1000 [00:28<00:10, 33.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:47.302159Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1623. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 144. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.303412Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.304228Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:47.306176Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 146. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1625. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1608. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.307518Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:47.307778Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.308265Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 132. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.309764Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.452758Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 115. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.453657Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.456809Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1599. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.457703Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.460331Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.460894Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.461368Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.461846Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.462098Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1613. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 133. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.462795Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.464062Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 104. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1583. Please try again in 474ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.464779Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.465235Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1648. Please try again in 494ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 169. Please try again in 50ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.465942Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.466021Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1599. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.466930Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.467900Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1585. Please try again in 475ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 106. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.468616Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.468973Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 105. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1585. Please try again in 475ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.469636Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.485092Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 106. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.485875Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.486311Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 168. Please try again in 50ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1648. Please try again in 494ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.487137Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.541832Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1673. Please try again in 501ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.542897Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  67%|██████▋   | 671/1000 [00:29<00:08, 40.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:47.906901Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1622. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.907413Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:47.908287Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.909231Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 138. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1617. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.910562Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 132. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198484, Requested 1611. Please try again in 28ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.910658Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:47.911292Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.911739Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.920973Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1622. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 142. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.921983Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.990116Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1658. Please try again in 497ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 178. Please try again in 53ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.991395Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.991908Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:47.991909Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 127. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 184. Please try again in 55ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1663. Please try again in 498ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.992932Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.993389Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:47.993413Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1621. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.994708Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:47.995618Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1593. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:47.996346Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.006899Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 137. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1617. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.007807Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.014558Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1630. Please try again in 488ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.015377Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.073065Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1600. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.073860Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.077744Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.078550Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.091196Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 117. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1596. Please try again in 478ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.093893Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  68%|██████▊   | 678/1000 [00:29<00:07, 45.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:48.112413Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199464, Requested 1580. Please try again in 313ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 101. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 183. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1663. Please try again in 498ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 120. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1599. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 100. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.112787Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:48.113233Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:48.113238Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:48.113923Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.114182Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:48.114310Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.114840Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.115661Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 140. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.117576Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  69%|██████▉   | 693/1000 [00:29<00:06, 43.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:48.323095Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 119. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.324886Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.325407Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1622. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.326151Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.328251Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.328814Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1600. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 121. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.329378Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.329958Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.330049Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:48.330807Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.331151Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:48.331528Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1606. Please try again in 481ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 126. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 119. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.334455Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.334697Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.354158Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1620. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 140. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.355065Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.356739Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1603. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 123. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.357519Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.359446Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 128. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1607. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.360115Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.362862Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.363527Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.387545Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1666. Please try again in 499ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.388349Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.389688Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 125. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.390430Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.489809Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.490571Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  70%|██████▉   | 699/1000 [00:30<00:08, 33.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:48.683670Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 131. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1611. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.684957Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.687892Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1602. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.688813Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1596. Please try again in 478ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 117. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.689000Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:48.689035Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1592. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 112. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.690135Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.690233Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 132. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1611. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.690985Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.691488Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.800346Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:48.800843Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:48.800857Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 158. Please try again in 47ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 120. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.800847Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:48.801260Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:48.801483Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1599. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199998, Requested 1610. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 131. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1601. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199407, Requested 1604. Please try again in 303ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.803566Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:48.804024Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.804247Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:48.804913Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.805139Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.805207Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:48.805281Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 140. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 135. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.807683Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.808352Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.808559Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:48.849075Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199868, Requested 1595. Please try again in 438ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 116. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.849940Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  71%|███████▏  | 714/1000 [00:30<00:06, 41.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:48.926612Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1601. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:48.927834Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.059688Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 134. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199303, Requested 1613. Please try again in 274ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.060175Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1631. Please try again in 489ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.060771Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.061202Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.061779Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.062481Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.062660Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:49.063259Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:49.063688Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1615. Please try again in 484ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.064275Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.072025Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.072945Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.076809Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 118. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199790, Requested 1597. Please try again in 416ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.077721Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.079227Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199037, Requested 1606. Please try again in 192ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 127. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.079996Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.083365Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 129. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199134, Requested 1608. Please try again in 222ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.084260Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.088365Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:49.088365Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1598. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.089390Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.089489Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 141. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199300, Requested 1620. Please try again in 276ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.090245Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.090907Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  73%|███████▎  | 728/1000 [00:30<00:05, 49.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:49.194462Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 132. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.195768Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.199207Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.200193Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.220527Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1588. Please try again in 476ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.222369Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.232226Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:49.232743Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199486, Requested 1649. Please try again in 340ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 170. Please try again in 51ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 146. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.233466Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.233867Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.243378Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1659. Please try again in 497ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 180. Please try again in 54ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.244105Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.247993Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 144. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.249163Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.297289Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:49.297721Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199348, Requested 1587. Please try again in 280ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199880, Requested 1610. Please try again in 447ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 131. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.298297Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.300726Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.429809Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1608. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.431330Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.628087Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199460, Requested 1602. Please try again in 318ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.629308Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 112. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199316, Requested 1591. Please try again in 272ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.629308Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:49.630001Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  75%|███████▍  | 747/1000 [00:31<00:05, 48.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:49.632278Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1604. Please try again in 481ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.634105Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.642639Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1599. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.643777Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.648204Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:49.648717Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 132. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199103, Requested 1611. Please try again in 214ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199895, Requested 1597. Please try again in 447ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.649430Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.650298Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.652178Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199853, Requested 1637. Please try again in 447ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.652937Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.702945Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199407, Requested 1612. Please try again in 305ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.703941Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.705936Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 144. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.706723Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 117. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.706770Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.706950Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:49.708033Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199252, Requested 1598. Please try again in 255ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 119. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.708662Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.711526Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.712484Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.715450Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1639. Please try again in 491ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.716573Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.719051Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 131. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.720142Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:49.720272Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.721313Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.724587Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 122. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.725547Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.760961Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 123. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199319, Requested 1602. Please try again in 276ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.761753Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.783150Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.784088Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.869392Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:49.870421Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:49.870421Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199855, Requested 1599. Please try again in 436ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 120. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.871863Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.872276Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1645. Please try again in 493ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.872385Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.872567Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.873488Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:49.883745Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1590. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:49.884560Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  76%|███████▋  | 764/1000 [00:31<00:05, 42.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:50.094668Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:50.095607Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199158, Requested 1604. Please try again in 228ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199934, Requested 124. Please try again in 17ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:50.096167Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:50.098759Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:50.141275Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:50.142121Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:50.148616Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1594. Please try again in 478ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:50.149879Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:50.156677Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199756, Requested 1607. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 128. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:50.157618Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:50.157931Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1623. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:50.158592Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:50.170851Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199959, Requested 1612. Please try again in 471ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:50.171798Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:50.171924Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1604. Please try again in 481ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:50.172705Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:50.173125Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:50.173781Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:50.175500Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199423, Requested 1612. Please try again in 310ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:50.176276Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:50.246624Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199971, Requested 1605. Please try again in 472ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:50.247371Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:50.254299Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1599. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:50.255123Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:50.386246Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 111. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199742, Requested 1590. Please try again in 399ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:50.387812Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  77%|███████▋  | 770/1000 [00:32<00:09, 25.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:50.808677Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:50.808677Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:50.809308Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198785, Requested 1607. Please try again in 117ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:50.810651Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:50.811279Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:50.811452Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:50.818846Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199640, Requested 1632. Please try again in 381ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:50.819536Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:50.934355Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:50.935145Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:50.935231Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199400, Requested 1605. Please try again in 301ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:50.936119Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:50.943248Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:50.943987Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  78%|███████▊  | 779/1000 [00:32<00:08, 25.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:51.051366Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198967, Requested 1689. Please try again in 196ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.052467Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199288, Requested 1601. Please try again in 266ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.052541Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:51.053471Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:51.141451Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.142294Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:51.174172Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 140. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.174977Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:51.175055Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199479, Requested 1604. Please try again in 324ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.175834Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:51.178576Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199338, Requested 1598. Please try again in 280ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 119. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.179645Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  78%|███████▊  | 783/1000 [00:32<00:09, 23.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:51.261231Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1648. Please try again in 494ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.262442Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:51.280161Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1585. Please try again in 475ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.280996Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:51.409148Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 150. Please try again in 45ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.409947Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:51.410267Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1603. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.410946Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:51.419854Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.420605Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:51.423335Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1618. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.424111Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:51.426031Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1616. Please try again in 484ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.426871Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:51.429321Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 111. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1590. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.430033Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:51.435616Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 121. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.436840Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  79%|███████▉  | 789/1000 [00:33<00:09, 22.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:51.679047Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:51.679907Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1633. Please try again in 489ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.680585Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:51.682380Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:51.686394Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1628. Please try again in 488ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.687241Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  80%|████████  | 805/1000 [00:33<00:05, 34.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:51.958020Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1613. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 133. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.959272Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:51.978652Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199986, Requested 1572. Please try again in 467ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.979509Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:51.987341Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.988230Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:51.988228Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199384, Requested 1585. Please try again in 290ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:51.989356Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.015558Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:52.015942Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199745, Requested 1598. Please try again in 402ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1620. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199543, Requested 1607. Please try again in 345ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.016310Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:52.016829Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.017109Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 117. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1597. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.017670Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.017933Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.018416Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.020466Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.021308Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.022103Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199526, Requested 1667. Please try again in 357ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.023000Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.029251Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199740, Requested 1587. Please try again in 398ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.030020Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.057506Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199998, Requested 154. Please try again in 45ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1633. Please try again in 489ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198467, Requested 1632. Please try again in 29ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.058157Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:52.058223Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.058967Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.059226Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199818, Requested 1601. Please try again in 425ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.059664Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:52.060124Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.060248Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199840, Requested 182. Please try again in 6ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.060744Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:52.061637Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:52.062790Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199350, Requested 1660. Please try again in 303ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1615. Please try again in 484ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199302, Requested 1604. Please try again in 271ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.063394Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.063551Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.063665Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.063866Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 138. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.065513Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.069016Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1595. Please try again in 478ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 116. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.069787Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.072175Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.072538Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199348, Requested 1703. Please try again in 315ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 224. Please try again in 67ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.073128Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:52.073196Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.073697Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.074139Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.085811Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199695, Requested 1619. Please try again in 394ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.086579Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.090504Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 143. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.091329Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  82%|████████▎ | 825/1000 [00:33<00:03, 44.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:52.300396Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199833, Requested 1606. Please try again in 431ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.300908Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:52.300911Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:52.300932Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:52.300950Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:52.300950Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:52.300978Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:52.301082Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1612. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199852, Requested 1654. Please try again in 451ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 152. Please try again in 45ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.302840Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199850, Requested 1613. Please try again in 438ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199914, Requested 1624. Please try again in 461ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.306059Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.306393Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.306777Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.306902Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.306983Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.308306Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.308538Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.424177Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.424971Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.425557Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:52.426958Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1611. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.429281Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.429960Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.441278Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199457, Requested 1587. Please try again in 313ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.442284Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.444307Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.445261Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.449338Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199206, Requested 1652. Please try again in 257ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 173. Please try again in 51ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.450391Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.462472Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.463188Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.467192Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199138, Requested 1660. Please try again in 239ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.468421Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.470513Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199436, Requested 1591. Please try again in 308ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.471555Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  84%|████████▍ | 842/1000 [00:34<00:03, 48.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:52.616270Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.617489Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:52.617904Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199068, Requested 1614. Please try again in 204ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.620488Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.666889Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199511, Requested 1637. Please try again in 344ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.667772Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.672827Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1609. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.673632Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.678991Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1629. Please try again in 488ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.680014Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.686124Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Request too large for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Requested 144. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198486, Requested 1623. Please try again in 32ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.687046Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.689077Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199326, Requested 1627. Please try again in 285ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.689848Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.691984Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199888, Requested 1651. Please try again in 461ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.692809Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.746904Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199776, Requested 1641. Please try again in 425ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.747945Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.809183Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.810134Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  85%|████████▍ | 848/1000 [00:34<00:04, 37.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:52.864715Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 126. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.865216Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:52.866748Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.867732Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.937314Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199909, Requested 1622. Please try again in 459ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 143. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.938176Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:52.938233Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198521, Requested 1605. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:52.939215Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.031686Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199618, Requested 1619. Please try again in 371ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.032612Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.034109Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199841, Requested 1633. Please try again in 442ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.035415Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  85%|████████▌ | 853/1000 [00:34<00:05, 25.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:53.270289Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 116. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.271599Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.438852Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1594. Please try again in 478ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.439678Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.447336Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.448150Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.457288Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.458200Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.458231Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.461971Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.466778Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199897, Requested 115. Please try again in 3ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.467536Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  86%|████████▌ | 858/1000 [00:34<00:05, 24.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:53.493495Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.494651Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.545336Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198519, Requested 1586. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.546129Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.671105Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199622, Requested 1594. Please try again in 364ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.671913Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.676422Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199707, Requested 1612. Please try again in 395ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.677253Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.677923Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199953, Requested 112. Please try again in 19ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199626, Requested 1592. Please try again in 365ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.678732Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.714259Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.715596Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.721453Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.722271Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.722579Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199906, Requested 114. Please try again in 6ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.723253Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.723657Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.724291Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.743119Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:53.743523Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 132. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199898, Requested 121. Please try again in 5ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199718, Requested 1600. Please try again in 395ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.744010Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:53.744286Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 129. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199993, Requested 1608. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.745168Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.745864Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  87%|████████▋ | 868/1000 [00:35<00:04, 28.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:53.930797Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 136. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199528, Requested 1615. Please try again in 342ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.931969Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:53.932339Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1624. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.935751Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.936211Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1594. Please try again in 478ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.937152Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1601. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.937374Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.938063Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.941842Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:53.942275Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:53.942279Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:53.942374Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199524, Requested 1614. Please try again in 341ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 134. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1612. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.943080Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:53.943319Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:53.943350Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.943979Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:53.944016Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.944175Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 138. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1635. Please try again in 490ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.944846Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 104. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.945368Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.945588Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.945893Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.954750Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 113. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199606, Requested 1592. Please try again in 359ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.955504Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.956329Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 134. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.956921Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:53.958223Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199672, Requested 1598. Please try again in 381ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:53.959126Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  90%|████████▉ | 895/1000 [00:35<00:02, 47.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:54.189338Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:54.189936Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1625. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 174. Please try again in 52ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.190858Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:54.193190Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:54.193724Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1613. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.195912Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:54.196080Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198900, Requested 1609. Please try again in 152ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.197277Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:54.221512Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 159. Please try again in 47ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.222646Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:54.224130Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.225008Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199697, Requested 1599. Please try again in 388ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.225043Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:54.226137Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:54.226695Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 149. Please try again in 44ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.227387Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:54.228830Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:54.228830Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1658. Please try again in 497ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199858, Requested 178. Please try again in 10ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.229762Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:54.229916Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:54.276552Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.277369Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:54.278812Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199599, Requested 1663. Please try again in 378ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.279503Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:54.280332Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.281047Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:54.325287Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 146. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199493, Requested 1625. Please try again in 335ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.326217Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:54.326870Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 147. Please try again in 44ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.329409Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:54.388299Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199783, Requested 1604. Please try again in 416ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 124. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.389088Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  91%|█████████ | 906/1000 [00:35<00:01, 57.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:54.391540Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:54.391939Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:54.391939Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198964, Requested 1624. Please try again in 176ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199883, Requested 123. Please try again in 1ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 128. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.393477Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:54.394355Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:54.394496Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:54.418884Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1609. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.419454Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:54.419454Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:54.419476Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.422681Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1664. Please try again in 499ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 185. Please try again in 55ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.429661Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 135. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1615. Please try again in 484ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.431045Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1590. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1628. Please try again in 488ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.432640Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:54.433914Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.437690Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1706. Please try again in 511ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 227. Please try again in 68ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  91%|█████████▏| 914/1000 [00:36<00:02, 39.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:54.810816Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 130. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.816350Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 110. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.818969Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.820270Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.821858Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 117. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.848884Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:54.870663Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199814, Requested 1614. Please try again in 428ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 135. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  92%|█████████▎| 925/1000 [00:36<00:02, 35.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:55.056048Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.058645Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.062492Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1613. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.195418Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1605. Please try again in 481ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 125. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.200775Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1654. Please try again in 496ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 175. Please try again in 52ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.204222Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:55.204701Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1590. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.207500Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  94%|█████████▍| 943/1000 [00:36<00:01, 49.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:55.307377Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1640. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1608. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1617. Please try again in 485ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 138. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1614. Please try again in 484ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 134. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1587. Please try again in 476ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 116. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1596. Please try again in 478ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1596. Please try again in 478ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 117. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.308448Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:55.308472Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:55.308457Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:55.308488Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:55.308448Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:55.308515Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:55.308531Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:55.308548Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1654. Please try again in 496ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.318998Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1601. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.320428Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1586. Please try again in 475ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 107. Please try again in 32ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.344356Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 176. Please try again in 52ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1655. Please try again in 496ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.347219Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1621. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 142. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.348314Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.368144Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 161. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1640. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.370411Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1621. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 141. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.372160Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1694. Please try again in 508ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.468166Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.468721Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.480300Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 141. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.498255Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1599. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 120. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  95%|█████████▌| 954/1000 [00:36<00:00, 58.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:55.542286Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1625. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.543654Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 112. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1591. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.549724Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 131. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1610. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.551230Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 186. Please try again in 55ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1665. Please try again in 499ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.552473Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1670. Please try again in 501ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 191. Please try again in 57ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.553525Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.562612Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1626. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 147. Please try again in 44ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.590442Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1621. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.600618Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.684687Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:55.685483Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:55.685500Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:55.685481Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 130. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1609. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 149. Please try again in 44ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.686722Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1623. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  97%|█████████▋| 969/1000 [00:37<00:00, 50.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:55.757704Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1611. Please try again in 483ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.770178Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:55.770212Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:55.770187Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:55.770682Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 111. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 154. Please try again in 46ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 114. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.771409Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1594. Please try again in 478ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 114. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.811115Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 107. Please try again in 32ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199922, Requested 1587. Please try again in 452ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.811657Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1642. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.944086Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 130. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199911, Requested 1609. Please try again in 456ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.945779Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1630. Please try again in 488ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 150. Please try again in 45ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.950483Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.952036Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1642. Please try again in 492ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.953800Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:55.954264Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.956359Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1608. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:55.957913Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199958, Requested 1584. Please try again in 462ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences:  99%|█████████▉| 988/1000 [00:37<00:00, 77.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:56.033339Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 150. Please try again in 45ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1629. Please try again in 488ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:56.034458Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:56.035822Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:56.036202Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 147. Please try again in 44ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1627. Please try again in 488ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:56.037143Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:56.037540Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1599. Please try again in 479ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1648. Please try again in 494ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:56.038148Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:56.039080Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:56.040414Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:56.040856Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1624. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 145. Please try again in 43ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 117. Please try again in 35ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:56.042078Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 124. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1603. Please try again in 480ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:56.052341Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1587. Please try again in 476ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199900, Requested 108. Please try again in 2ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:56.180461Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 152. Please try again in 45ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:56.180868Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1620. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:56.181440Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 103. Please try again in 30ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199564, Requested 1705. Please try again in 380ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 226. Please try again in 67ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:56.182262Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running training inferences: 100%|██████████| 1000/1000 [00:37<00:00, 26.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:56.394784Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1658. Please try again in 497ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:56.397226Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:56.398304Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:56.400248Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:56.400248Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:56.400252Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:56.400252Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 198598, Requested 1599. Please try again in 59ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 120. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 1593. Please try again in 477ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199078, Requested 1583. Please try again in 198ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:56.403610Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 151. Please try again in 45ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\\ngpt_4o_mini_optimized: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAINING_INFERENCES = 1000\n",
    "\n",
    "coroutines = [\n",
    "    run_inference(example) for example in train_examples[:NUM_TRAINING_INFERENCES]\n",
    "]\n",
    "\n",
    "results = await tqdm_asyncio.gather(*coroutines, desc=\"Running training inferences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we evaluate the accuracy of a variant on some of the test examples. If you generate a new variant, you should run this cell with the new variant name to evaluate it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running test inferences:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:56.430154Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.430309Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.430396Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.430492Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.430574Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.430661Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.430747Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.430838Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.430919Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.431027Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.431149Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.431247Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.431344Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.431457Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.431539Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.431632Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.431743Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.431845Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.431921Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.432002Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.432067Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.432139Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.432204Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.432293Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.432380Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.432447Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.432511Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.432574Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.432638Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.432727Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.433185Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.433376Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.433504Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.433656Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.433765Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.433904Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.434036Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.434152Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.434290Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.434401Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.434508Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.434620Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.434718Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.434832Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.435214Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.435400Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.435522Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.435632Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.435733Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.435839Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.435943Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.436056Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.436382Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.436619Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.436852Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.437027Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.437128Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.437206Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.437307Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.437383Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.437528Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.437619Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.437674Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.437723Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.437782Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.437844Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.437920Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.437975Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.438025Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.438080Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.438146Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.440461Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.440607Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.440693Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.440863Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.441005Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.441110Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.441217Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.441307Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.441403Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.441474Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.441535Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.441587Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.441638Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.441692Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.441752Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.441856Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.441978Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.442066Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.442448Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.442572Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.442647Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.442720Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.442787Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.442853Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.442919Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.442994Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.443065Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.443134Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:56.443204Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running test inferences:   0%|          | 1/200 [00:00<02:35,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:57.209262Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:57.210137Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running test inferences:   1%|          | 2/200 [00:01<01:32,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:57.454880Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:57.455358Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:57.456380Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:57.456380Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:57.456466Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:57.456482Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:57.457539Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:57.459024Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:57.459996Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:57.460441Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:57.460550Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:57.460648Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running test inferences:   6%|▌         | 11/200 [00:01<00:16, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:57.685161Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:57.685982Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:57.686440Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:57.686899Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:57.688429Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:57.689039Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:57.844287Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:57.845064Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:57.846000Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:57.848634Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:57.853071Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:57.853995Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:57.854460Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:57.855255Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:57.857024Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:57.858095Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:57.858989Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:57.859735Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:57.859747Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:57.860169Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:57.860885Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:57.860894Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:57.861200Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:57.862279Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:57.863588Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:57.864326Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running test inferences:  10%|█         | 21/200 [00:01<00:07, 25.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:57.971707Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:57.973070Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:57.977083Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:57.977894Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:57.982911Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:57.984150Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:57.986867Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:57.988139Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:58.057007Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:58.057876Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running test inferences:  13%|█▎        | 26/200 [00:01<00:07, 23.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:58.207758Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:58.208865Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:58.228906Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:58.229635Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:58.279300Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:58.280119Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running test inferences:  15%|█▌        | 30/200 [00:02<00:09, 17.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:58.594717Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:58.595625Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:58.595637Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:58.595625Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:58.596253Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:58.596887Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:58.597034Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:58.599094Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:58.605457Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:58.606197Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:58.606211Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:58.606879Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:58.608870Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:58.609531Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:58.623235Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:58.623675Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:58.624182Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:58.624625Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:58.629060Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:58.629735Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:58.652438Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:58.653105Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:58.655375Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:58.656039Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running test inferences:  24%|██▎       | 47/200 [00:02<00:07, 21.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:59.140626Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:59.140626Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:59.141354Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.141930Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:59.142100Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.142285Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.145575Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.147873Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.148044Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.148141Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.156318Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.157062Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.309375Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.309918Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:59.310380Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.310585Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:59.310796Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:59.311434Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:59.312926Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.313111Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.313942Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.315022Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.315184Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.315296Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.315939Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.316146Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.328614Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.329684Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.330933Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.331792Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.336349Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.337248Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.342294Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.344367Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running test inferences:  31%|███       | 62/200 [00:03<00:05, 25.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:59.682806Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.684767Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.721140Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.721647Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:59.721978Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.722312Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:59.722448Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.723070Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.808589Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.809313Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.812609Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.813388Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:59.813414Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.814103Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.814228Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.814876Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.815830Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.816568Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.817963Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.818543Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.818898Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.819286Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.820413Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.821030Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.823426Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.824150Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.824598Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.825150Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.825667Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.826406Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.828626Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.829477Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.833425Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.834158Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.836856Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.837411Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.837512Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.838087Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.838246Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:59.838743Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.840331Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.840816Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:59.841172Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.841394Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T09:59:59.841897Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.842474Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running test inferences:  44%|████▎     | 87/200 [00:03<00:02, 45.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T09:59:59.966012Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.967530Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.971780Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.972581Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.973537Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.974259Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T09:59:59.974277Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T09:59:59.975130Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T10:00:00.095194Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.095770Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.096318Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.096339Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.097266Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.097327Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T10:00:00.098157Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T10:00:00.098331Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.099127Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.101900Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.102577Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T10:00:00.102739Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T10:00:00.104600Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.105213Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.105812Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.105974Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T10:00:00.106606Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.107400Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.108204Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.108728Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T10:00:00.108826Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.108929Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.110088Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T10:00:00.110234Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T10:00:00.110832Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.111628Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T10:00:00.111699Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.112623Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.113294Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T10:00:00.113384Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.114236Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T10:00:00.114861Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero::client_input\u001b[0m\u001b[2m:\u001b[0m Deprecation Warning: passing in an object for `content` is deprecated. Please use an array of content blocks instead.\n",
      "\u001b[2m2025-08-12T10:00:00.119189Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.121670Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.123951Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.126677Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.127206Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.129516Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.140588Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.145278Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.152324Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.152324Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.153140Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.155129Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.155129Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running test inferences:  69%|██████▉   | 138/200 [00:04<00:00, 85.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T10:00:00.382403Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.383915Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 160. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.385270Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.385278Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.385270Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.386076Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.387081Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 139. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 124. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 130. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 141. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.389927Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 129. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.392711Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.393291Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 113. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.395753Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 123. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.397962Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 152. Please try again in 45ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.405641Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.405640Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.405664Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.405640Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.405693Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.405703Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.405713Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.405721Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.406206Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.406474Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 139. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 112. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 132. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 142. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 106. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 139. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 136. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.421216Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.422899Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.533445Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 130. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.540881Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 104. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.541908Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 130. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.546083Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.546453Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.548985Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 127. Please try again in 38ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.551729Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 138. Please try again in 41ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.552260Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.593321Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.596301Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.597804Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 133. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.599411Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 110. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.607969Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.608306Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 156. Please try again in 46ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.608949Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.609732Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running test inferences:  83%|████████▎ | 166/200 [00:04<00:00, 67.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T10:00:00.880918Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 136. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.883078Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.883078Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199929, Requested 141. Please try again in 21ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.888954Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.888954Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 133. Please try again in 39ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.889644Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 160. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.894552Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 114. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.895008Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:00.900868Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.906531Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.915537Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:00.926971Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:01.072429Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:01.073464Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:01.075825Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:01.077357Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:01.081644Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:01.081700Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199925, Requested 131. Please try again in 16ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 126. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 199960, Requested 145. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:01.084974Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:01.086534Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:01.094626Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:01.095510Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 104. Please try again in 31ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:01.100061Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:01.104283Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 151. Please try again in 45ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:01.107412Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:01.107996Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:01.108019Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:01.107996Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:01.108094Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:01.108147Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:01.108543Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:01.108653Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:01.109613Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 141. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:01.111300Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running test inferences: 100%|██████████| 200/200 [00:04<00:00, 40.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-12T10:00:01.334900Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:01.335604Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:01.335604Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:01.335604Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:01.335609Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:01.335609Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:01.335674Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:01.335688Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:01.335700Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 124. Please try again in 37ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 113. Please try again in 33ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 136. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 142. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "\u001b[2m2025-08-12T10:00:01.336758Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:01.336872Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:01.337153Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "\u001b[2m2025-08-12T10:00:01.338266Z\u001b[0m \u001b[33m WARN\u001b[0m \u001b[2mtensorzero_internal::error\u001b[0m\u001b[2m:\u001b[0m Request failed: HTTP status server error (502 Bad Gateway) for url (http://localhost:3000/inference)\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 140. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"requests\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Error (<class 'tensorzero.types.TensorZeroError'>): TensorZeroError (status code 502): {\"error\":\"All variants failed with errors: gpt_4o_mini_baseline: All model providers failed to infer with errors: openai: Error 429 Too Many Requests from openai client: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Rate limit reached for gpt-4o-mini in organization org-2UNBOwAjq6LkaA8Fl347aXVc on tokens per min (TPM): Limit 200000, Used 200000, Requested 135. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.\\\",\\n        \\\"type\\\": \\\"tokens\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"rate_limit_exceeded\\\"\\n    }\\n}\\n\"}\n",
      "Success rate: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m success_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;241m/\u001b[39m total_results\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccess rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuccess_rate\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(results) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(results)\n\u001b[1;32m     27\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(results)\n\u001b[1;32m     28\u001b[0m z \u001b[38;5;241m=\u001b[39m norm\u001b[38;5;241m.\u001b[39mppf(\u001b[38;5;241m0.975\u001b[39m)  \u001b[38;5;66;03m# 95% confidence interval\u001b[39;00m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "NUM_TEST_INFERENCES = 200\n",
    "\n",
    "VARIANTS = [\n",
    "    \"gpt_4o_mini_baseline\",\n",
    "    # The provided optimized variant was generated by DSPy using the code below\n",
    "    # \"gpt_4o_mini_optimized\",\n",
    "]\n",
    "\n",
    "accuracies = {}\n",
    "\n",
    "for variant_name in VARIANTS:\n",
    "    # We use dryrun=True here to avoid leaking the test set into the database\n",
    "    coroutines = [\n",
    "        run_inference(example, variant_name=variant_name, dryrun=True)\n",
    "        for example in test_examples[:NUM_TEST_INFERENCES]\n",
    "    ]\n",
    "\n",
    "    results = await tqdm_asyncio.gather(*coroutines, desc=\"Running test inferences\")\n",
    "\n",
    "    # Filter out None values from results\n",
    "    total_results = len(results)\n",
    "    results = [result for result in results if result is not None]\n",
    "    success_rate = len(results) / total_results\n",
    "    print(f\"Success rate: {success_rate:.1%}\")\n",
    "\n",
    "    accuracy = sum(results) / len(results)\n",
    "    n = len(results)\n",
    "    z = norm.ppf(0.975)  # 95% confidence interval\n",
    "    margin_of_error = z * np.sqrt((accuracy * (1 - accuracy)) / n)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\n",
    "        f\"95% Confidence Interval: ({accuracy - margin_of_error:.4f}, {accuracy + margin_of_error:.4f})\"\n",
    "    )\n",
    "\n",
    "    accuracies[variant_name] = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(\n",
    "    [\n",
    "        {\"Variant\": variant_name, \"Score\": accuracy}\n",
    "        for variant_name, accuracy in accuracies.items()\n",
    "    ]\n",
    ")\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = (\n",
    "    alt.Chart(scores_df)\n",
    "    .encode(\n",
    "        x=alt.X(\"Score:Q\", axis=alt.Axis(format=\"%\"), scale=alt.Scale(domain=[0, 1])),\n",
    "        y=\"Variant:N\",\n",
    "        text=alt.Text(\"Score:Q\", format=\".1%\"),\n",
    "    )\n",
    "    .properties(title=\"Metrics by Variant\")\n",
    ")\n",
    "\n",
    "chart = chart.mark_bar() + chart.mark_text(align=\"left\", dx=2)\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we could run any TensorZero recipe to generate a new variant which might perform better using this historical data. You can go try this!\n",
    "\n",
    "Below, we include an example of how to use an external library, [DSPy](https://dspy-docs.vercel.app/), to automatically optimize a prompt for this function.\n",
    "Given that the ClickHouse database TensorZero uses easily allows for the querying of historical inference and feedback data into Pandas DataFrames, it is easy to integrate with nearly any ML library yourself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Prompt Engineering with DSPy\n",
    "\n",
    "The rest of this notebook shows how we can pull data from the TensorZero data model in ClickHouse and use it to optimize a prompt for a function using DSPy.\n",
    "Given that there are many strategies for prompt optimization in DSPy, we can use the same code skeleton to try a lot of different strategies.\n",
    "However, there are a few things (table name, feedback name, chat function type, etc) that we have set specifically for this example.\n",
    "You can change them to fit your needs.\n",
    "At a high level the notebook below does the following:\n",
    "\n",
    "1. Pull data from ClickHouse and convert it into a DSPy dataset.\n",
    "2. Run a prompt optimization loop using one of the teleprompting classes supported by DSPy.\n",
    "3. Print the optimized prompt from the history so that you can write it to a minijinja file.\n",
    "\n",
    "**Note:** DSPy does not model the chat completion interface commonly used by language models. So, we only support functions that have inputs into the user prompt, that only use text output, that are single-turn functions, and that have a flat JSON schema for input, i.e. functions that take a list of primitive types as input into the user schema and output text or a flat JSON object.\n",
    "\n",
    "To get started:\n",
    "\n",
    "- Set the `TENSORZERO_CLICKHOUSE_URL` environment variable. \n",
    "- Set the `OPENAI_API_KEY` environment variable.\n",
    "- Update the following parameters to those that apply to your use case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from clickhouse_connect import get_client\n",
    "from dspy.datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can swap the client below for any of the ones supported [here](https://dspy.ai/learn/programming/language_models/) in case you want DSPy to use a different language model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_client = dspy.OpenAI(model=\"gpt-4o-mini\")\n",
    "dspy.configure(lm=lm_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple function signature for the `solve_math_problem` function\n",
    "function_signature = \"input -> output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the ClickHouse client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"TENSORZERO_CLICKHOUSE_URL\" in os.environ, (\n",
    "    \"TENSORZERO_CLICKHOUSE_URL environment variable not set\"\n",
    ")\n",
    "clickhouse_client = get_client(dsn=os.environ[\"TENSORZERO_CLICKHOUSE_URL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the dataset of examples which were successful according to the metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    i.variant_name, \n",
    "    i.input, \n",
    "    i.output, \n",
    "    i.episode_id,\n",
    "    f.value\n",
    "FROM \n",
    "    ChatInference i\n",
    "JOIN \n",
    "    (SELECT\n",
    "        target_id,\n",
    "        value,\n",
    "        ROW_NUMBER() OVER (PARTITION BY target_id ORDER BY timestamp DESC) as rn\n",
    "    FROM BooleanMetricFeedback\n",
    "    WHERE\n",
    "        metric_name = 'correct'\n",
    "        AND value = true\n",
    "    ) f ON i.id = f.target_id and f.rn = 1\n",
    "WHERE \n",
    "    i.function_name = 'solve_math_problem'\n",
    "LIMIT %(max_samples)s\n",
    "\"\"\"\n",
    "\n",
    "params = {\n",
    "    \"max_samples\": 1000,\n",
    "}\n",
    "\n",
    "df = clickhouse_client.query_df(query, params)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dspy_compatible_inputs(input_raw: str) -> Optional[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Checks that the input of this Inference is in the correct format for DSPy.\n",
    "    Then returns the dictionary of inputs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parsed_input = json.loads(input_raw)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Input is not valid JSON: {input_raw}\")\n",
    "        return None\n",
    "    messages = parsed_input.get(\"messages\", None)\n",
    "    if messages is None:\n",
    "        print(f\"Input contains no messages: {input_raw}\")\n",
    "        return None\n",
    "    if len(messages) != 1:\n",
    "        print(f\"Input contains more than one message: {input_raw}\")\n",
    "        return None\n",
    "    message = messages[0]\n",
    "    content = message.get(\"content\", None)\n",
    "    if content is None:\n",
    "        print(f\"Input contains no content: {input_raw}\")\n",
    "        return None\n",
    "    if len(content) != 1:\n",
    "        print(f\"Input must contain exactly one content item: {input_raw}\")\n",
    "        return None\n",
    "    content = content[0]\n",
    "    if content[\"type\"] != \"text\":\n",
    "        print(f\"Input contains non-text content: {input_raw}\")\n",
    "        return None\n",
    "    value = content.get(\"value\", None)\n",
    "    if value is None:\n",
    "        print(f\"Input contains no value: {input_raw}\")\n",
    "        return None\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the input column into a list of dicts and create a new DataFrame with parsed content\n",
    "parsed_inputs = df[\"input\"].apply(parse_dspy_compatible_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_outputs(output_raw: str) -> Optional[str]:\n",
    "    try:\n",
    "        parsed_output = json.loads(output_raw)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Output is not valid JSON: {output_raw}\")\n",
    "        return None\n",
    "    if len(parsed_output) != 1:\n",
    "        print(f\"Output contains more than one message: {output_raw}\")\n",
    "        return None\n",
    "    message = parsed_output[0]\n",
    "    if message[\"type\"] != \"text\":\n",
    "        print(f\"Output contains non-text content: {output_raw}\")\n",
    "        return None\n",
    "    value = message.get(\"text\", None)\n",
    "    if value is None:\n",
    "        print(f\"Output contains no value: {output_raw}\")\n",
    "        return None\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the output column and create a new DataFrame with parsed content\n",
    "parsed_outputs = df[\"output\"].apply(parse_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([parsed_inputs, parsed_outputs], axis=1)\n",
    "all_data = all_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorZeroDSPyDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        dev_fraction: float = 0.1,\n",
    "    ):\n",
    "        # Randomly shuffle the DataFrame\n",
    "        df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "        # Extract the 'question' string from the 'input' column\n",
    "        df[\"input\"] = df[\"input\"].apply(lambda x: x[\"question\"])\n",
    "\n",
    "        # Calculate the number of samples for train and dev sets\n",
    "        total_samples = len(df)\n",
    "        dev_samples = int(total_samples * dev_fraction)\n",
    "        train_samples = total_samples - dev_samples\n",
    "\n",
    "        # Split the DataFrame\n",
    "        train_df = df.iloc[:train_samples]\n",
    "        dev_df = df.iloc[train_samples:]\n",
    "\n",
    "        # Split the DataFrame\n",
    "        self._train = train_df.to_dict(orient=\"records\")\n",
    "        self._dev = dev_df.to_dict(orient=\"records\")\n",
    "        self._test = None\n",
    "        self.train_size = len(self._train)\n",
    "        self.dev_size = len(self._dev)\n",
    "        super().__init__(\n",
    "            train_size=self.train_size,\n",
    "            dev_size=self.dev_size,\n",
    "            test_size=0,\n",
    "        )\n",
    "\n",
    "        print(f\"Train set: {len(self._train)} samples\")\n",
    "        print(f\"Dev set: {len(self._dev)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorZeroDSPyDataset(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy_function = dspy.Predict(function_signature)\n",
    "\n",
    "\n",
    "class Predictor(dspy.Module):\n",
    "    def __init__(self, signature: dspy.Signature):\n",
    "        super().__init__()\n",
    "        self.prog = dspy.Predict(signature)\n",
    "\n",
    "    def forward(self, **inputs):\n",
    "        return self.prog(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can swap the teleprompter with any of the teleprompting classes supported by DSPy [here](https://dspy-docs.vercel.app/docs/building-blocks/optimizers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import LabeledFewShot\n",
    "\n",
    "teleprompter = LabeledFewShot(k=5)\n",
    "optimized_function = teleprompter.compile(\n",
    "    Predictor(function_signature), trainset=dataset.train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.dev[0][\"input\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run an example inference to get the prompt from the history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_function(input=\"test_input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's parse out the prompt from the history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy_prompt = lm_client.history[-1][\"prompt\"]\n",
    "# we parse the actual inference input out of the prompt (DSPy does not separate the prompt from the inputs in this history)\n",
    "dspy_prompt = \"---\".join(dspy_prompt.split(\"---\")[:-1])\n",
    "\n",
    "# DSPy does not know the output format for GSM8k, so we add it manually\n",
    "merged_prompt = f\"\"\"\n",
    "You are tasked with solving a math problem. You will be given an open-ended question that should require arithmetic to solve.\n",
    "\n",
    "Feel free to work through the problem step-by-step in your response, but once you have found the solution, please complete your response with:\n",
    "#### your_answer\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "{dspy_prompt}\n",
    "\n",
    "---\n",
    "\n",
    "REMEMBER: End your response with `#### your_answer`, where `your_answer` should be an integer with no other punctuation.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(merged_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the optimized user prompt to a minijinja file and try it out! You can skip to the training cell and use the new variant name to evaluate.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
